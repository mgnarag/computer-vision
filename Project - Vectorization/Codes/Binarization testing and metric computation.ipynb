{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mgnarag/binarization-autoencoder/blob/main/Testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4a6w1GsajIN",
        "outputId": "3d6ccd9c-8c09-4778-f55b-9836acdfa1db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKh0dJSzaj_X"
      },
      "outputs": [],
      "source": [
        "!ls drive/My\\ Drive\n",
        "file_path = \"/content/drive/My Drive/Architectural_designs/one quadrant/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7KGh6L6qVZ8b"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "from PIL import Image, ImageOps\n",
        "Image.MAX_IMAGE_PIXELS = None\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "import time\n",
        "import os\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "4TkaTAC3zgr7"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def crop(im):\n",
        "    width, height = im.size\n",
        "    data = []\n",
        "    for j in range(0,int(height/n_size)):\n",
        "        for i in range(0,int(width/n_size)):\n",
        "            im1 = im.crop((0 + (n_size*i), 0 + (n_size*j), n_size + (n_size*i), n_size + (n_size*j)))\n",
        "            im1 = np.array(im1)\n",
        "            im1 = im1.astype(np.float32)\n",
        "            im1 = im1/255\n",
        "            data.append(im1)\n",
        "    return data\n",
        "\n",
        "def normalize(arr):\n",
        "    \"\"\"\n",
        "    Linear normalization\n",
        "    http://en.wikipedia.org/wiki/Normalization_%28image_processing%29\n",
        "    \"\"\"\n",
        "    arr = arr.astype('float')\n",
        "    # Do not touch the alpha channel\n",
        "    for i in range(3):\n",
        "        minval = arr[...,i].min()\n",
        "        maxval = arr[...,i].max()\n",
        "        if minval != maxval:\n",
        "            arr[...,i] -= minval\n",
        "            arr[...,i] *= (255.0/(maxval-minval))\n",
        "    return arr\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdJThYVg8IpL"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tEw3HC_48ce",
        "outputId": "a9115d1a-3d33-40b3-df0a-98b71c3be091"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model =  1\n",
            "Model =  2\n",
            "Model =  3\n",
            "Model =  4\n",
            "Model =  5\n",
            "Model =  6\n",
            "Model =  7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-6d19e0da9514>:85: RuntimeWarning: invalid value encountered in long_scalars\n",
            "  precision = tp / (tp + fp)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model =  8\n"
          ]
        }
      ],
      "source": [
        "gt = Image.open(file_path+ '4 Testing/ground_truth.png').convert('L')\n",
        "img_gt = cv2.imread(file_path+ '4 Testing/ground_truth.png')\n",
        "gt = gt.crop((0, 0, 9728, 7168))\n",
        "img_gt = img_gt[0:7168 , 0:9728]\n",
        "gt = np.asarray(gt) > 128\n",
        "gt = ~gt\n",
        "\n",
        "filename = \"1.png\"\n",
        "directory = file_path + '4 Testing/' + filename\n",
        "#directory = 'test_output_v'+str(model)+'.png'\n",
        "dirty = ImageOps.grayscale(Image.open(directory))\n",
        "dirty = np.array(dirty)\n",
        "dirty = Image.fromarray(normalize(dirty).astype('uint8'))\n",
        "\n",
        "w_dirty, h_dirty = dirty.size\n",
        "\n",
        "\n",
        "METRIC = []\n",
        "\n",
        "for model in range(1,9):\n",
        "    print('Model = ', model)\n",
        "    from tensorflow import keras\n",
        "    autoencoder = keras.models.load_model(file_path + '1 Models/autoencoder_'+str(model))\n",
        "    if model == 1:\n",
        "        n_size = 32\n",
        "    if model == 2:\n",
        "        n_size = 32\n",
        "    if model == 3:\n",
        "        n_size = 64\n",
        "    if model == 4:\n",
        "        n_size = 64\n",
        "    if model == 5:\n",
        "        n_size = 128\n",
        "    if model == 6:\n",
        "        n_size = 128\n",
        "    if model == 7:\n",
        "        n_size = 256\n",
        "    if model == 8:\n",
        "        n_size = 256\n",
        "\n",
        "    xx = int(w_dirty/n_size)\n",
        "    final=[]\n",
        "\n",
        "    for portion in range(0,xx):\n",
        "        #print(\"current portion to clean:\", str(portion))\n",
        "\n",
        "        im1 = dirty.crop((n_size*portion, 0, (n_size*portion) + n_size, h_dirty-128))\n",
        "        w1, h1 = im1.size\n",
        "        w = int(w1/n_size)\n",
        "        h = int(h1/n_size)\n",
        "\n",
        "        neverbeforeseen = np.array(crop(im1))\n",
        "        encoded_imgs = autoencoder.encoder(neverbeforeseen).numpy()\n",
        "        decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()\n",
        "\n",
        "        col = np.vstack((decoded_imgs[0],decoded_imgs[1]))\n",
        "        for i in range(2,h):\n",
        "            col = np.vstack((col,decoded_imgs[i]))\n",
        "\n",
        "        y = np.where(col > 0.5,1,0) #round the values\n",
        "        y = (y * 255).astype('uint8')\n",
        "        if portion == 0:\n",
        "            final = y\n",
        "        if portion > 0:\n",
        "            final = np.hstack((final,y))\n",
        "\n",
        "    final = np.squeeze(final)\n",
        "    reconstructed = Image.fromarray(final)\n",
        "    reconstructed.save(file_path + \"5 Tested/output v\" + str(model) + '.png')\n",
        "\n",
        "    output = Image.open(file_path + \"5 Tested/output v\" + str(model) + '.png').convert('L')  # convert to grayscale\n",
        "    img_out = cv2.imread(file_path + \"5 Tested/output v\" + str(model) + '.png')\n",
        "\n",
        "    output = output.crop((0, 0, 9728, 7168))\n",
        "    img_out = img_out[0:7168 , 0:9728]\n",
        "\n",
        "    psnr = cv2.PSNR(img_out, img_gt)\n",
        "    # Convert to binary images\n",
        "    output = np.asarray(output) > 128\n",
        "    output = ~output\n",
        "\n",
        "    tp = np.sum(output & gt)\n",
        "    fp = np.sum(output & ~gt)\n",
        "    fn = np.sum(~output & gt)\n",
        "    precision = tp / (tp + fp)\n",
        "    recall = tp / (tp + fn)\n",
        "    f1score = (2*precision*recall)/(precision + recall)\n",
        "\n",
        "    I_1 = output & gt\n",
        "    O_1 = output | gt\n",
        "    I = np.sum(output & gt)\n",
        "    O = np.sum(output | gt)\n",
        "    i_o_u = I/O\n",
        "    METRIC.append([model, precision,recall,f1score,i_o_u,psnr])\n",
        "\n",
        "METRIC = pd.DataFrame(METRIC)\n",
        "\n",
        "headers = ['Model','Precision', 'Recall', 'F1 Score', 'IOU','PSNR' ]\n",
        "METRIC.columns = headers\n",
        "\n",
        "METRIC.to_csv(file_path + 'Metric.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gt = Image.open(file_path+ '4 Testing/ground_truth.png').convert('L')\n",
        "img_gt = cv2.imread(file_path+ '4 Testing/ground_truth.png')\n",
        "gt = gt.crop((0, 0, 9728, 7168))\n",
        "img_gt = img_gt[0:7168 , 0:9728]\n",
        "gt = np.asarray(gt) > 128\n",
        "gt = ~gt\n",
        "\n",
        "filename = \"1.png\"\n",
        "directory = file_path + '4 Testing/' + filename\n",
        "#directory = 'test_output_v'+str(model)+'.png'\n",
        "dirty = ImageOps.grayscale(Image.open(directory))\n",
        "dirty = np.array(dirty)\n",
        "dirty = Image.fromarray(normalize(dirty).astype('uint8'))\n",
        "\n",
        "w_dirty, h_dirty = dirty.size\n",
        "\n",
        "\n",
        "METRIC = []\n",
        "\n",
        "for model in range(1,9):\n",
        "    print('Model = ', model)\n",
        "    from tensorflow import keras\n",
        "    autoencoder = keras.models.load_model(file_path + '1 Models/autoencoder_'+str(model)+'_b')\n",
        "    if model == 1:\n",
        "        n_size = 32\n",
        "    if model == 2:\n",
        "        n_size = 32\n",
        "    if model == 3:\n",
        "        n_size = 64\n",
        "    if model == 4:\n",
        "        n_size = 64\n",
        "    if model == 5:\n",
        "        n_size = 128\n",
        "    if model == 6:\n",
        "        n_size = 128\n",
        "    if model == 7:\n",
        "        n_size = 256\n",
        "    if model == 8:\n",
        "        n_size = 256\n",
        "\n",
        "    xx = int(w_dirty/n_size)\n",
        "    final=[]\n",
        "\n",
        "    for portion in range(0,xx):\n",
        "        #print(\"current portion to clean:\", str(portion))\n",
        "\n",
        "        im1 = dirty.crop((n_size*portion, 0, (n_size*portion) + n_size, h_dirty-128))\n",
        "        w1, h1 = im1.size\n",
        "        w = int(w1/n_size)\n",
        "        h = int(h1/n_size)\n",
        "\n",
        "        neverbeforeseen = np.array(crop(im1))\n",
        "        encoded_imgs = autoencoder.encoder(neverbeforeseen).numpy()\n",
        "        decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()\n",
        "\n",
        "        col = np.vstack((decoded_imgs[0],decoded_imgs[1]))\n",
        "        for i in range(2,h):\n",
        "            col = np.vstack((col,decoded_imgs[i]))\n",
        "\n",
        "        y = np.where(col > 0.5,1,0) #round the values\n",
        "        y = (y * 255).astype('uint8')\n",
        "        if portion == 0:\n",
        "            final = y\n",
        "        if portion > 0:\n",
        "            final = np.hstack((final,y))\n",
        "\n",
        "    final = np.squeeze(final)\n",
        "    reconstructed = Image.fromarray(final)\n",
        "    reconstructed.save(file_path + \"5 Tested/output v\" + str(model) + '_b.png')\n",
        "\n",
        "    output = Image.open(file_path + \"5 Tested/output v\" + str(model) + '_b.png').convert('L')  # convert to grayscale\n",
        "    img_out = cv2.imread(file_path + \"5 Tested/output v\" + str(model) + '_b.png')\n",
        "\n",
        "    output = output.crop((0, 0, 9728, 7168))\n",
        "    img_out = img_out[0:7168 , 0:9728]\n",
        "\n",
        "    psnr = cv2.PSNR(img_out, img_gt)\n",
        "    # Convert to binary images\n",
        "    output = np.asarray(output) > 128\n",
        "    output = ~output\n",
        "\n",
        "    tp = np.sum(output & gt)\n",
        "    fp = np.sum(output & ~gt)\n",
        "    fn = np.sum(~output & gt)\n",
        "    precision = tp / (tp + fp)\n",
        "    recall = tp / (tp + fn)\n",
        "    f1score = (2*precision*recall)/(precision + recall)\n",
        "\n",
        "    I_1 = output & gt\n",
        "    O_1 = output | gt\n",
        "    I = np.sum(output & gt)\n",
        "    O = np.sum(output | gt)\n",
        "    i_o_u = I/O\n",
        "    METRIC.append([model, precision,recall,f1score,i_o_u,psnr])\n",
        "\n",
        "METRIC = pd.DataFrame(METRIC)\n",
        "\n",
        "headers = ['Model','Precision', 'Recall', 'F1 Score', 'IOU','PSNR' ]\n",
        "METRIC.columns = headers\n",
        "\n",
        "METRIC.to_csv(file_path + 'Metric_b.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QGS4v1CobWV",
        "outputId": "f06e28a1-d755-4c01-adfc-2d0e12b968a8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model =  1\n",
            "Model =  2\n",
            "Model =  3\n",
            "Model =  4\n",
            "Model =  5\n",
            "Model =  6\n",
            "Model =  7\n",
            "Model =  8\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}